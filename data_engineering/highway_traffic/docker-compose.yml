x-spark-common: &spark-common
  image: bitnami/spark:latest
  volumes:
    - ./scripts:/opt/bitnami/spark/scripts
  command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
  depends_on:
    - spark-master
  environment:
    SPARK_MODE: Worker
    SPARK_WORKER_CORES: 2
    SPARK_WORKER_MEMORY: 1g
    SPARK_MASTER_URL: spark://spark-master:7077
  deploy:
    resources:
      limits:
        cpus: '1'
        memory: 1G
  networks:
    - highway_network

services:
  yolo:
    build:
      context: .                
      dockerfile: Dockerfile
    container_name: yolo_kafka_spark_service
    volumes:
      - ./scripts:/app
    working_dir: /app
    environment:
      - PYTHONUNBUFFERED=1
    depends_on:
      - spark-master
      - postgres
      # - clickhouse-server
      - kafka
    networks:
      - highway_network
    command: ["tail", "-f", "/dev/null"]
    # command: ["python", "yolo_script.py"]

  kafka:
    image: confluentinc/cp-kafka:7.5.2
    container_name: kafka_service
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka:9093' 
      KAFKA_LISTENERS: 'PLAINTEXT://:9092,CONTROLLER://:9093' 
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://127.0.0.1:9092' 
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1 
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1 
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1 
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        
    volumes:
      - kafka_data:/var/lib/kafka/data 
    networks:
      - highway_network

  spark-master:
    image: bitnami/spark:latest
    command: bin/spark-class org.apache.spark.deploy.master.Master
    ports:
      - "9090:8080"
      - "7077:7077"
    networks:
      - highway_network
  spark-worker-1:
    <<: *spark-common
  spark-worker-2:
    <<: *spark-common

  postgres: 
      image: postgres:14 
      container_name: highway-postgres-instance
      ports:
        - "5432:5432"
      networks:
        - highway_network
      volumes:
        - postgres_data:/var/lib/postgresql/data 
      environment:
        POSTGRES_USER: 'spark_user' 
        POSTGRES_PASSWORD: 'spark_password' 
        POSTGRES_DB: 'highway_traffic' 
      restart: always
      deploy:
        resources:
          limits:
            memory: 2G # Adjust as needed
  
  dbt:
    image: ghcr.io/dbt-labs/dbt-postgres:1.9.0
    platform: linux/amd64
    container_name: dbt_highway_psql_app
    networks:
      - highway_network
    volumes:
      - ./dbt_highway_psql/profiles.yml:/root/.dbt/profiles.yml
      - ./dbt_highway_psql:/dbt
    working_dir: /usr/app/dbt_project
    environment:
      DBT_PROFILE: dbt_highway_psql
      DBT_TARGET: dev
    depends_on:
      - postgres

networks:
  highway_network:
    driver: bridge

volumes: 
  kafka_data:
  postgres_data: # New volume for PostgreSQL data