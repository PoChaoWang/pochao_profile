x-spark-common: &spark-common
  image: bitnami/spark:latest
  volumes:
    - ./scripts:/opt/bitnami/spark/scripts
  command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
  depends_on:
    - spark-master
  environment:
    SPARK_MODE: Worker
    SPARK_WORKER_CORES: 2
    SPARK_WORKER_MEMORY: 1g
    SPARK_MASTER_URL: spark://spark-master:7077
  deploy:
    resources:
      limits:
        cpus: '1'
        memory: 1G
  networks:
    - highway_network

services:
  yolo:
    build:
      context: .                
      dockerfile: Dockerfile
    container_name: yolo_kafka_spark_service
    volumes:
      - ./scripts:/app
    working_dir: /app
    environment:
      - PYTHONUNBUFFERED=1
    depends_on:
      - spark-master
      - postgres
      # - clickhouse-server
      - kafka
    networks:
      - highway_network
    command: ["tail", "-f", "/dev/null"]
    # command: ["python", "yolo_script.py"]

  kafka:
    image: confluentinc/cp-kafka:7.5.2
    container_name: kafka_service
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka:9093' 
      KAFKA_LISTENERS: 'PLAINTEXT://:9092,CONTROLLER://:9093' 
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://127.0.0.1:9092' 
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1 
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1 
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1 
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'
      # KAFKA_LOG_DIRS: "/var/lib/kafka/data" # 如果需要指定日誌目錄
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        
    volumes:
      - kafka_data:/var/lib/kafka/data # 持久化 Kafka 數據
    networks:
      - highway_network

  spark-master:
    image: bitnami/spark:latest
    # volumes:
    #   - ./:/opt/bitnami/spark/
    command: bin/spark-class org.apache.spark.deploy.master.Master
    ports:
      - "9090:8080"
      - "7077:7077"
    networks:
      - highway_network
  spark-worker-1:
    <<: *spark-common
  spark-worker-2:
    <<: *spark-common

  # clickhouse-server:
  #   image: clickhouse/clickhouse-server:25.4.4.25
  #   container_name: highway-clickhouse-instance  
  #   ports:
  #     - "8123:8123"  
  #     - "9000:9000"  
  #   networks:
  #     - highway_network
  #   volumes:
  #     - ./my_clickhouse_config/users.d:/etc/clickhouse-server/users.d
  #     - ./clickhouse_data:/var/lib/clickhouse
  #     - ./clickhouse_logs:/var/log/clickhouse-server
  #   environment:
  #     CLICKHOUSE_USER: 'spark_user'
  #     CLICKHOUSE_PASSWORD: 'spark_password'
  #     CLICKHOUSE_DB: 'spark_db'
  #   ulimits: 
  #     nproc: 65535
  #     nofile:
  #       soft: 262144
  #       hard: 262144
  #   restart: always
  #   deploy:
  #     resources:
  #       limits:
  #         memory: 4G

  # dbt-clickhouse-service:
  #   build:
  #     context: .  
  #     dockerfile: dbt_highway_traffic/Dockerfile 
  #   container_name: dbt_clickhouse_app
  #   working_dir: /usr/app/dbt_highway_traffic 
  #   volumes:
  #     - ./dbt_highway_traffic:/usr/app/dbt_highway_traffic
  #     - ~/.dbt:/root/.dbt
      
  #   networks:
  #     - highway_network
  #   depends_on:
  #     - clickhouse-server
  #   tty: true       
  #   stdin_open: true 
  #   command: tail -f /dev/null 

  postgres: # New PostgreSQL service
      image: postgres:14 # Using a specific version is good practice, you can use 'latest'
      container_name: highway-postgres-instance
      ports:
        - "5432:5432"
      networks:
        - highway_network
      volumes:
        - postgres_data:/var/lib/postgresql/data # Persistent data for PostgreSQL
      environment:
        POSTGRES_USER: 'spark_user' # Or your desired username
        POSTGRES_PASSWORD: 'spark_password' # Or your desired password
        POSTGRES_DB: 'highway_traffic' # Or your desired database name
      restart: always
      deploy:
        resources:
          limits:
            memory: 2G # Adjust as needed
  
  dbt:
    image: ghcr.io/dbt-labs/dbt-postgres:1.9.0
    platform: linux/amd64
    container_name: dbt_highway_psql_app
    networks:
      - highway_network
    volumes:
      - ~/.dbt:/root
      - ./dbt_highway_psql:/dbt
    working_dir: /usr/app/dbt_project
    environment:
      DBT_PROFILE: dbt_highway_psql
      DBT_TARGET: dev
    depends_on:
      - postgres

networks:
  highway_network:
    driver: bridge

volumes: # 定義持久化卷
  kafka_data:
  postgres_data: # New volume for PostgreSQL data